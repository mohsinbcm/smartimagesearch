# Smart Image Search Engine

A local machine-based semantic image search system that indexes images, generates embeddings, and enables natural language description-based search.

## ğŸ¯ Project Overview

Build a smart image search engine that:
- Scans and indexes all images on your local machine
- Generates embeddings using vision-language models
- Enables semantic search using natural language descriptions
- Runs entirely offline on local hardware

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interface                        â”‚
â”‚              (Web UI / CLI / Desktop App)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Search API Layer                         â”‚
â”‚         - Query Processing                               â”‚
â”‚         - Result Ranking                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Store  â”‚    â”‚  Metadata Store   â”‚
â”‚   (FAISS/      â”‚    â”‚   (SQLite/        â”‚
â”‚   ChromaDB)    â”‚    â”‚   PostgreSQL)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Image Processing Layer          â”‚
â”‚  - Image Discovery & Crawling           â”‚
â”‚  - Embedding Generation (CLIP/BLIP)     â”‚
â”‚  - Face Detection & Recognition          â”‚
â”‚  - Thumbnail Generation                  â”‚
â”‚  - Metadata Extraction                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technology Stack

### Core Components

1. **Image Embedding Models**
   - **Primary**: OpenAI CLIP (ViT-L/14 or ViT-B/32)
   - **Alternative**: BLIP, BLIP-2, or LLaVA for better captioning
   - **Lightweight**: MobileCLIP for faster inference

2. **Face Recognition**
   - **Detection**: MTCNN, RetinaFace, or YuNet
   - **Recognition**: FaceNet, ArcFace, or InsightFace
   - **Clustering**: DBSCAN or HDBSCAN for grouping faces
   - **Libraries**: `deepface`, `face_recognition`, or `insightface`

3. **Vector Database**
   - **FAISS**: Facebook's similarity search library (fast, local)
   - **ChromaDB**: Open-source embedding database
   - **Alternative**: Qdrant, Weaviate, or Milvus

4. **Metadata Database**
   - **SQLite**: Lightweight, serverless (recommended for local)
   - **PostgreSQL**: More robust, with pgvector extension

5. **Backend Framework**
   - **Python**: FastAPI or Flask
   - **Libraries**: 
     - `transformers` (Hugging Face)
     - `torch` or `onnxruntime`
     - `Pillow` for image processing
     - `watchdog` for file monitoring

6. **Frontend**
   - **Web UI**: React/Vue.js + Tailwind CSS
   - **Desktop App**: Electron or Tauri
   - **CLI**: Rich/Typer for terminal interface

## ğŸ“‹ Implementation Plan

### Phase 1: Project Setup & Image Discovery (Week 1)

#### 1.1 Environment Setup
```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: venv\Scripts\activate

# Install core dependencies
pip install torch torchvision transformers pillow
pip install faiss-cpu chromadb sqlalchemy
pip install fastapi uvicorn python-multipart
pip install watchdog tqdm python-dotenv
pip install deepface insightface opencv-python
```

#### 1.2 Image Crawler Implementation
- **Goal**: Recursively scan directories for image files
- **Features**:
  - Support formats: JPG, PNG, GIF, BMP, TIFF, WebP, HEIC
  - Configurable directory exclusions (temp, cache, system folders)
  - Handle symlinks and permissions errors
  - Progress tracking and resumable scanning
  - File change detection using hash (SHA-256)

**Key Files**:
- `src/crawler/image_scanner.py` - Main scanner logic
- `src/crawler/file_watcher.py` - Monitor for new/changed images
- `config/scan_paths.yaml` - Configurable paths and exclusions

#### 1.3 Metadata Extraction
- **EXIF Data**: GPS, camera info, timestamp
- **File Metadata**: Size, format, dimensions, creation date
- **Computed Hashes**: For duplicate detection

**Schema Design**:
```sql
CREATE TABLE images (
    id INTEGER PRIMARY KEY,
    file_path TEXT UNIQUE NOT NULL,
    file_hash TEXT NOT NULL,
    file_size INTEGER,
    width INTEGER,
    height INTEGER,
    format TEXT,
    created_at DATETIME,
    modified_at DATETIME,
    exif_data JSON,
    indexed_at DATETIME,
    embedding_version TEXT
);

CREATE TABLE tags (
    id INTEGER PRIMARY KEY,
    name TEXT UNIQUE NOT NULL
);

CREATE TABLE image_tags (
    image_id INTEGER,
    tag_id INTEGER,
    confidence REAL,
    FOREIGN KEY (image_id) REFERENCES images(id),
    FOREIGN KEY (tag_id) REFERENCES tags(id)
);

CREATE TABLE persons (
    id INTEGER PRIMARY KEY,
    name TEXT,
    face_embedding BLOB,
    thumbnail_path TEXT,
    created_at DATETIME,
    updated_at DATETIME,
    notes TEXT
);

CREATE TABLE faces (
    id INTEGER PRIMARY KEY,
    image_id INTEGER,
    person_id INTEGER,
    bbox_x INTEGER,
    bbox_y INTEGER,
    bbox_width INTEGER,
    bbox_height INTEGER,
    face_embedding BLOB,
    confidence REAL,
    verified BOOLEAN DEFAULT FALSE,
    detected_at DATETIME,
    FOREIGN KEY (image_id) REFERENCES images(id),
    FOREIGN KEY (person_id) REFERENCES persons(id)
);

CREATE TABLE person_clusters (
    id INTEGER PRIMARY KEY,
    cluster_label INTEGER,
    representative_face_id INTEGER,
    image_count INTEGER,
    created_at DATETIME,
    FOREIGN KEY (representative_face_id) REFERENCES faces(id)
);
```

### Phase 2: Embedding Generation (Week 2)

#### 2.1 Model Selection & Loading
```python
# Example: CLIP model loading
from transformers import CLIPProcessor, CLIPModel

model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")
```

**Model Comparison**:
| Model | Size | Speed | Quality | Use Case |
|-------|------|-------|---------|----------|
| CLIP ViT-B/32 | ~350MB | Fast | Good | Quick indexing |
| CLIP ViT-L/14 | ~890MB | Medium | Excellent | Best quality |
| MobileCLIP | ~40MB | Very Fast | Fair | Resource-constrained |
| BLIP-2 | ~2.7GB | Slow | Excellent | Detailed captions |

#### 2.2 Batch Processing Pipeline
- **Goal**: Process 10,000+ images efficiently
- **Strategy**:
  - Batch size: 32-64 images (adjust based on GPU memory)
  - Image preprocessing: Resize to 224x224 or 336x336
  - Multi-threading for I/O operations
  - GPU acceleration if available
  - Progress persistence for crash recovery

**Key Features**:
- Dynamic batching based on image sizes
- Memory-efficient loading (don't load all images at once)
- Error handling for corrupt images
- Thumbnail generation for UI display

**Performance Targets**:
- CPU: ~5-10 images/second
- GPU (NVIDIA RTX 3060): ~50-100 images/second

#### 2.3 Embedding Storage
```python
# Vector dimensions
CLIP_ViT_B_32 = 512
CLIP_ViT_L_14 = 768

# FAISS index creation
import faiss
index = faiss.IndexFlatIP(768)  # Inner product for cosine similarity
index = faiss.IndexIVFFlat(quantizer, 768, 100)  # Faster for large datasets
```

### Phase 2.5: Face Recognition & Person Directory (Week 2-3)

#### 2.5.1 Face Detection
- **Goal**: Detect all faces in indexed images
- **Strategy**:
  - Use MTCNN or RetinaFace for face detection
  - Extract bounding boxes and face crops
  - Store face coordinates in database
  - Generate face thumbnails for preview

**Implementation**:
```python
from deepface import DeepFace
import cv2

def detect_faces(image_path):
    # Detect faces in image
    faces = DeepFace.extract_faces(
        img_path=image_path,
        detector_backend='retinaface',
        enforce_detection=False
    )
    return faces
```

#### 2.5.2 Face Recognition & Embedding
- **Goal**: Generate embeddings for each detected face
- **Model Options**:
  - **FaceNet**: 128-dimensional embeddings
  - **ArcFace**: 512-dimensional embeddings (better accuracy)
  - **VGG-Face**: Deep learning based

**Implementation**:
```python
from insightface.app import FaceAnalysis

app = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
app.prepare(ctx_id=0, det_size=(640, 640))

def get_face_embedding(image, bbox):
    # Extract face region
    face_crop = image[bbox[1]:bbox[3], bbox[0]:bbox[2]]
    
    # Get embedding
    faces = app.get(face_crop)
    if faces:
        return faces[0].embedding
    return None
```

#### 2.5.3 Face Clustering
- **Goal**: Automatically group similar faces together
- **Algorithm**: DBSCAN or HDBSCAN for density-based clustering
- **Strategy**:
  - Compute pairwise distances between face embeddings
  - Cluster faces with similar features
  - Each cluster represents a potential person
  - User can review and merge/split clusters

**Implementation**:
```python
from sklearn.cluster import DBSCAN
import numpy as np

def cluster_faces(face_embeddings, eps=0.5, min_samples=3):
    # Normalize embeddings
    embeddings = np.array(face_embeddings)
    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
    
    # Cluster using DBSCAN
    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine')
    labels = clustering.fit_predict(embeddings)
    
    return labels
```

#### 2.5.4 Person Directory
- **Goal**: Create and manage person profiles
- **Features**:
  - Assign names to face clusters
  - View all images containing a specific person
  - Merge duplicate person entries
  - Manual face tagging and verification
  - Person statistics (photo count, date range)
  - Representative face thumbnail for each person

**Key Files**:
- `src/face_recognition/detector.py` - Face detection
- `src/face_recognition/embedder.py` - Face embedding generation
- `src/face_recognition/clusterer.py` - Face clustering
- `src/face_recognition/person_manager.py` - Person directory management

**Person Directory Features**:
```python
class PersonDirectory:
    def create_person(name: str, face_ids: list) -> Person
    def merge_persons(person_id1: int, person_id2: int) -> Person
    def assign_face_to_person(face_id: int, person_id: int) -> bool
    def get_person_images(person_id: int) -> list[Image]
    def search_by_person(person_ids: list) -> list[Image]
    def get_person_statistics(person_id: int) -> dict
```

### Phase 3: Vector Search Implementation (Week 3-4)

#### 3.1 Vector Database Setup

**Option A: FAISS** (Recommended for local use)
```python
import faiss
import numpy as np

# Create index
dimension = 768
index = faiss.IndexFlatL2(dimension)  # L2 distance
# OR
index = faiss.IndexFlatIP(dimension)  # Cosine similarity

# Add embeddings
embeddings = np.array([...])  # Shape: (n_images, 768)
index.add(embeddings)

# Save/Load
faiss.write_index(index, "image_embeddings.index")
index = faiss.read_index("image_embeddings.index")
```

**Option B: ChromaDB** (Better for metadata filtering)
```python
import chromadb

client = chromadb.PersistentClient(path="./chroma_db")
collection = client.create_collection(
    name="image_embeddings",
    metadata={"hnsw:space": "cosine"}
)

# Add images with metadata
collection.add(
    embeddings=embeddings,
    documents=image_paths,
    metadatas=metadata_list,
    ids=image_ids
)
```

#### 3.2 Query Processing
```python
def search_images(query_text, top_k=20):
    # 1. Generate text embedding
    text_embedding = encode_text(query_text)
    
    # 2. Search vector store
    distances, indices = index.search(text_embedding, top_k)
    
    # 3. Fetch metadata from SQL
    results = []
    for idx, distance in zip(indices[0], distances[0]):
        image_info = get_image_metadata(idx)
        results.append({
            'path': image_info['path'],
            'score': float(distance),
            'metadata': image_info
        })
    
    return results
```

#### 3.3 Advanced Search Features
- **Hybrid Search**: Combine semantic + metadata filters
- **Re-ranking**: Use CLIP scores + metadata relevance
- **Query Expansion**: "cat" â†’ ["cat", "kitten", "feline"]
- **Multi-modal**: Search with image + text
- **Fuzzy Search**: Handle typos and variations

### Phase 4: API & Backend (Week 4)

#### 4.1 REST API Design
```python
# FastAPI implementation
from fastapi import FastAPI, UploadFile, Query
from pydantic import BaseModel

app = FastAPI()

@app.post("/search")
async def search(
    query: str,
    top_k: int = 20,
    filters: dict = None
):
    results = search_images(query, top_k, filters)
    return {"results": results}

@app.post("/index/scan")
async def trigger_scan(paths: list[str]):
    # Start background indexing task
    task_id = start_indexing_task(paths)
    return {"task_id": task_id, "status": "started"}

@app.get("/index/status")
async def get_index_status():
    return {
        "total_images": count_indexed_images(),
        "last_updated": get_last_update_time(),
        "indexing_progress": get_current_progress()
    }

@app.post("/search/image")
async def search_by_image(file: UploadFile):
    # Search similar images
    image = load_image(file)
    embedding = encode_image(image)
    results = vector_search(embedding)
    return {"results": results}

@app.get("/persons")
async def list_persons(skip: int = 0, limit: int = 100):
    # Get all persons in directory
    persons = get_all_persons(skip, limit)
    return {"persons": persons}

@app.get("/persons/{person_id}")
async def get_person(person_id: int):
    # Get person details and images
    person = get_person_by_id(person_id)
    images = get_person_images(person_id)
    return {"person": person, "images": images}

@app.post("/persons/{person_id}/images")
async def search_by_person(person_id: int, filters: dict = None):
    # Search images containing specific person
    results = search_images_by_person(person_id, filters)
    return {"results": results}

@app.post("/persons/create")
async def create_person(name: str, face_ids: list[int]):
    # Create new person from face cluster
    person = create_person_profile(name, face_ids)
    return {"person": person}

@app.put("/persons/{person_id}")
async def update_person(person_id: int, name: str = None):
    # Update person information
    person = update_person_info(person_id, name)
    return {"person": person}
```

#### 4.2 Background Tasks
- **Async Indexing**: Use Celery or RQ for job queue
- **Incremental Updates**: Monitor file system changes
- **Auto Re-indexing**: Detect moved/renamed files

#### 4.3 Caching Layer
- **Query Cache**: Redis for frequent queries
- **Thumbnail Cache**: Pre-generated thumbnails
- **Embedding Cache**: Avoid re-computing unchanged images

### Phase 5: User Interface (Week 5)

#### 5.1 Web UI Features
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Smart Image Search                    [âš™ï¸]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  [Search: "sunset over mountains"     ğŸ”]   â”‚
â”‚                                             â”‚
â”‚  Filters: [Dateâ–¾] [Formatâ–¾] [Sizeâ–¾] [Personâ–¾] â”‚
â”‚                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Results (245 images)              [Gridâ–¾]  â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”           â”‚
â”‚  â”‚ğŸ“· â”‚ â”‚ğŸ“· â”‚ â”‚ğŸ“· â”‚ â”‚ğŸ“· â”‚ â”‚ğŸ“· â”‚           â”‚
â”‚  â”‚85%â”‚ â”‚82%â”‚ â”‚79%â”‚ â”‚75%â”‚ â”‚72%â”‚           â”‚
â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜           â”‚
â”‚  /path/1  /path/2  /path/3  ...            â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”           â”‚
â”‚  â”‚ğŸ“· â”‚ â”‚ğŸ“· â”‚ â”‚ğŸ“· â”‚ â”‚ğŸ“· â”‚ â”‚ğŸ“· â”‚           â”‚
â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜           â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Components**:
- Search bar with autocomplete
- Grid/List view toggle
- Image preview modal
- Metadata display panel
- Export results functionality
- Drag & drop image search
- Filter sidebar (date, format, size, location)

#### 5.2 CLI Tool
```bash
# Search
smartsearch query "golden retriever puppy"

# Index new directory
smartsearch index --path /path/to/photos --recursive

# Status
smartsearch status

# Export results
smartsearch query "vacation photos" --export results.json

# Person-related commands
smartsearch persons list
smartsearch persons show <person_id>
smartsearch persons create --name "John Doe" --faces 1,2,3
smartsearch persons search --person <person_id>
smartsearch faces cluster --review
```

### Phase 6: Optimization & Enhancement (Week 6+)

#### 6.1 Performance Optimization
- **Quantization**: Use INT8 quantization for faster inference
- **ONNX Runtime**: Convert model to ONNX for better performance
- **Index Optimization**: Use IVF or HNSW for large datasets (>100K images)
- **Lazy Loading**: Load thumbnails on-demand
- **Pagination**: Implement cursor-based pagination

#### 6.2 Advanced Features
1. **Duplicate Detection**: Find similar/identical images using perceptual hashing
2. **Person-based Search**: Filter and search by recognized individuals
3. **Face Verification**: Manually verify and correct face assignments
4. **Person Merge/Split**: Combine duplicate persons or separate incorrectly grouped faces
5. **OCR Integration**: Search text in images using Tesseract/EasyOCR
6. **Auto-Tagging**: Generate tags using vision models
7. **Color Search**: "images with mostly blue tones"
8. **Smart Albums**: Auto-organize by content (events, locations, people)
9. **Timeline View**: Chronological browsing with person filtering
10. **Geolocation**: Map-based image search
11. **Face Timeline**: Track individuals across time
12. **Unknown Faces**: Review and identify unrecognized faces

#### 6.3 Model Fine-tuning
- Fine-tune CLIP on your personal image collection
- Use contrastive learning with user feedback
- Implement relevance feedback loop

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- 8GB RAM minimum (16GB recommended)
- GPU with 4GB+ VRAM (optional but recommended)
- 5GB disk space for models and index

### Quick Start
```bash
# Clone repository (once created)
git clone https://github.com/yourusername/smartimagesearch.git
cd smartimagesearch

# Install dependencies
pip install -r requirements.txt

# Configure scan paths
cp config/scan_paths.example.yaml config/scan_paths.yaml
# Edit config/scan_paths.yaml to add your image directories

# Initialize database
python -m src.database.init_db

# Start indexing
python -m src.cli index --path ~/Pictures

# Start API server
python -m src.api.server

# Open web UI
# Navigate to http://localhost:8000
```

## ğŸ“ Project Structure

```
smartimagesearch/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ scan_paths.yaml          # Directories to scan
â”‚   â”œâ”€â”€ model_config.yaml        # Model settings
â”‚   â””â”€â”€ search_config.yaml       # Search parameters
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ database.db              # SQLite database
â”‚   â”œâ”€â”€ embeddings.index         # FAISS index
â”‚   â”œâ”€â”€ thumbnails/              # Generated thumbnails
â”‚   â””â”€â”€ cache/                   # Query cache
â”œâ”€â”€ models/
â”‚   â””â”€â”€ clip/                    # Downloaded models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crawler/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ image_scanner.py    # Directory scanning
â”‚   â”‚   â”œâ”€â”€ file_watcher.py     # File system monitoring
â”‚   â”‚   â””â”€â”€ metadata_extractor.py
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model_manager.py    # Model loading
â”‚   â”‚   â”œâ”€â”€ image_encoder.py    # Image encoding
â”‚   â”‚   â””â”€â”€ text_encoder.py     # Text encoding
â”‚   â”œâ”€â”€ face_recognition/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ detector.py         # Face detection
â”‚   â”‚   â”œâ”€â”€ embedder.py         # Face embeddings
â”‚   â”‚   â”œâ”€â”€ clusterer.py        # Face clustering
â”‚   â”‚   â””â”€â”€ person_manager.py   # Person directory
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py           # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ init_db.py          # Database initialization
â”‚   â”‚   â””â”€â”€ queries.py          # Database operations
â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # FAISS operations
â”‚   â”‚   â”œâ”€â”€ query_processor.py  # Query handling
â”‚   â”‚   â””â”€â”€ ranker.py           # Result ranking
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ server.py           # FastAPI app
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py
â”‚   â”‚   â”‚   â”œâ”€â”€ index.py
â”‚   â”‚   â”‚   â”œâ”€â”€ persons.py
â”‚   â”‚   â”‚   â””â”€â”€ admin.py
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main.py             # CLI commands
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ image_processing.py
â”‚       â”œâ”€â”€ logging_config.py
â”‚       â””â”€â”€ progress_tracker.py
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_crawler.py
â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â””â”€â”€ test_search.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ setup.py
```

## ğŸ¯ Milestones & Deliverables

### Milestone 1: Core Indexing (Week 1-2)
- âœ… Image scanner with progress tracking
- âœ… Metadata extraction and storage
- âœ… Embedding generation pipeline
- âœ… Basic vector storage

### Milestone 2: Face Recognition & Search (Week 3)
- âœ… Face detection and embedding generation
- âœ… Face clustering and person directory
- âœ… Text-to-image search
- âœ… Person-based image filtering
- âœ… Top-K retrieval with scores
- âœ… Basic filtering by metadata

### Milestone 3: API & Interface (Week 4-5)
- âœ… REST API endpoints
- âœ… Web UI with search and results
- âœ… CLI tool for power users

### Milestone 4: Production Ready (Week 6+)
- âœ… Performance optimization
- âœ… Error handling and logging
- âœ… Documentation and tests
- âœ… Deployment scripts

## âš¡ Performance Considerations

### Indexing Performance
- **Target**: Index 100,000 images in ~4 hours (CPU) or ~30 minutes (GPU)
- **Strategies**:
  - Use batch processing (32-64 images)
  - Multi-process image loading
  - Incremental indexing
  - Skip unchanged files (hash comparison)

### Search Performance
- **Target**: <100ms for most queries
- **Strategies**:
  - Use FAISS GPU for >100K images
  - Implement query result caching
  - Pre-compute common queries
  - Use approximate nearest neighbor (ANN)

### Storage Estimates
- **Image Embeddings**: ~3KB per image (768 dimensions Ã— 4 bytes)
  - 100K images = ~300MB
  - 1M images = ~3GB
- **Face Embeddings**: ~2KB per face (512 dimensions Ã— 4 bytes)
  - 100K faces = ~200MB
  - Avg 1-2 faces per image
- **Thumbnails**: ~20KB per image
  - 100K images = ~2GB
- **Face Thumbnails**: ~5KB per face
  - 100K faces = ~500MB
- **Database**: ~1-2KB per image (metadata + face info)
  - 100K images = ~100-200MB

## ğŸ”’ Privacy & Security

- **Offline-First**: All processing happens locally
- **No Cloud Upload**: Images never leave your machine
- **Encrypted Storage**: Option to encrypt index at rest
- **Access Control**: Optional password protection
- **Audit Logs**: Track all file access

## ğŸ› Troubleshooting

### Common Issues
1. **Out of Memory**: Reduce batch size, use CPU mode
2. **Slow Indexing**: Enable GPU, reduce image resolution
3. **Poor Results**: Try different CLIP model, adjust similarity threshold
4. **Corrupt Index**: Re-index from scratch with backup

## ğŸ“š Resources

### Documentation
- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [FAISS Documentation](https://github.com/facebookresearch/faiss/wiki)
- [ChromaDB Docs](https://docs.trychroma.com/)

### Similar Projects
- Google Photos
- Apple Photos
- Adobe Lightroom
- [clip-retrieval](https://github.com/rom1504/clip-retrieval)

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Additional embedding models
- UI/UX enhancements
- Performance optimizations
- Documentation improvements

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ—ºï¸ Roadmap

### v1.0 (Current)
- Basic text-to-image search
- Local file indexing
- Face recognition and person directory
- Person-based search and filtering
- Web UI with person management

### v2.0 (Future)
- Mobile app (iOS/Android)
- Cloud sync (optional)
- Advanced face verification workflow
- Video frame indexing
- Face timeline and analytics
- Multi-language support
- Plugin system

### v3.0 (Vision)
- Distributed indexing
- Collaborative tagging
- AI-powered organization
- Advanced analytics

---

**Status**: ğŸš§ Planning Phase  
**Last Updated**: December 31, 2025  
**Maintainer**: Syed Mohd Mohsin Akhtar
